{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.platform import gfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DAAATASET\n",
    "\"\"\"\n",
    "DEBUG = False\n",
    "PATH_TRAIN = os.getcwd()+'/data/train'\n",
    "PATH_TEST = os.getcwd()+'/data/test'\n",
    "BATCH_SIZE = 10\n",
    "ITERATIONS = 2000\n",
    "ITERATIONS_TEST = 10\n",
    "EVAL_EVERY = 5\n",
    "HEIGHT = 25\n",
    "WIDTH = 64\n",
    "PAD_WIDTH = 300\n",
    "NUM_LABELS = 0\n",
    "LEARNING_RATE = 1E-4\n",
    "LOGDIR = 'log/'\n",
    "TEST_LOGDIR = 'log_test/'\n",
    "LABEL_TO_INDEX_MAP = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init(path):\n",
    "    labels = os.listdir(path)\n",
    "    index = 0\n",
    "    for label in labels:\n",
    "        LABEL_TO_INDEX_MAP[label] = index\n",
    "        index += 1\n",
    "        \n",
    "    global NUM_LABELS\n",
    "    NUM_LABELS = len(LABEL_TO_INDEX_MAP)\n",
    "    print(LABEL_TO_INDEX_MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(label):\n",
    "    encoding = [0] * len(LABEL_TO_INDEX_MAP)\n",
    "    encoding[LABEL_TO_INDEX_MAP[label]] = 1\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfcc(wave_path, PAD_WIDTH=WIDTH):\n",
    "    if DEBUG:\n",
    "        print(wave_path)\n",
    "    wave, sr = librosa.load(wave_path, mono=True, duration=0.7)\n",
    "    mfccs = librosa.feature.mfcc(y=wave, sr=sr, n_mfcc=HEIGHT)\n",
    "    mfccs = np.pad(mfccs,((0,0), (0, PAD_WIDTH - len(mfccs[0]))), mode='constant')\n",
    "    return mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(batch_size, path):\n",
    "    X = []\n",
    "    Y = []\n",
    "    random.seed(5896)\n",
    "    path = os.path.join(path,'*', '*.wav')\n",
    "    waves = gfile.Glob(path)\n",
    "    while True:\n",
    "        random.shuffle(waves)\n",
    "        for wave_path in waves:\n",
    "            _,label = os.path.split(os.path.dirname(wave_path))\n",
    "            X.append(get_mfcc(wave_path))\n",
    "            Y.append(one_hot_encoding(label))\n",
    "\n",
    "            if (len(X) == batch_size):\n",
    "                yield X, Y\n",
    "                X = []\n",
    "                Y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(input, dropout):\n",
    "    #topology\n",
    "    #.1. Convolutional Layer -> Relu -> dropout -> maxpool\n",
    "    # 2. Convolutional layer -> relu-> dropout\n",
    "    # 3.fully connected layer -> matmul\n",
    "    \n",
    "    #first convolutional\n",
    "    with tf.name_scope('Conv1'):\n",
    "        input_4D = tf.reshape(input, [-1, HEIGHT, WIDTH, 1])\n",
    "        w1 = tf.Variable(tf.truncated_normal([12,8,1,44], stddev=0.01), name=\"W\")\n",
    "        b1 = tf.Variable(tf.zeros([44]),name=\"B\")\n",
    "        conv1 = tf.nn.conv2d(input_4D, w1, strides=[1,1,1,1],padding=\"SAME\" )\n",
    "        act1 = tf.nn.relu(conv1 + b1)\n",
    "        drop1 = tf.nn.dropout(act1, dropout)\n",
    "        max_pool1 = tf.nn.max_pool(drop1,ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n",
    "        tf.summary.histogram('weight',w1)\n",
    "        tf.summary.histogram('biases',b1)\n",
    "        tf.summary.histogram('activations', act1)\n",
    "        tf.summary.histogram('dropouts',drop1)\n",
    "        \n",
    "    with tf.name_scope('Conv2'):\n",
    "        w2 = tf.Variable(tf.truncated_normal([6,4,44,44],stddev=0.01), name=\"W\")\n",
    "        b2 = tf.Variable(tf.zeros([44]), name=\"B\")\n",
    "        conv2 = tf.nn.conv2d(max_pool1, w2, strides=[1,1,1,1],padding='SAME')\n",
    "        act2 = tf.nn.relu(conv2+b2)\n",
    "        drop2 = tf.nn.dropout(act2, dropout)\n",
    "        tf.summary.histogram('weight',w2)\n",
    "        tf.summary.histogram(\"biases\",b2)\n",
    "        tf.summary.histogram('activations',act2)\n",
    "        tf.summary.histogram('dropouts',drop2)\n",
    "        \n",
    "    #Reshaping for Fully connected layer\n",
    "    conv_shape = drop2.get_shape()\n",
    "    count = int(conv_shape[1] * conv_shape[2] * conv_shape[3])\n",
    "    flat_output = tf.reshape(drop2,[-1,count])\n",
    "    \n",
    "    #fully connected layer\n",
    "    with tf.name_scope('FC'):\n",
    "        w3 = tf.Variable(tf.truncated_normal([count,NUM_LABELS],stddev=0.01))\n",
    "        b3 = tf.Variable(tf.zeros([NUM_LABELS]))\n",
    "        fc = tf.add(tf.matmul(flat_output,w3),b3)\n",
    "        tf.summary.histogram('weight',w3)\n",
    "        tf.summary.histogram('biases',b3)\n",
    "        \n",
    "    return fc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    #starting tensorflow graph and session\n",
    "    tf.reset_default_graph()\n",
    "    sess = tf.Session()\n",
    "    \n",
    "    #placeholder for input\n",
    "    x = tf.placeholder(tf.float32, shape=[None, HEIGHT, WIDTH], name='input')\n",
    "    \n",
    "    #placeholder for label\n",
    "    y = tf.placeholder(tf.float32, shape=[None, NUM_LABELS], name='label')\n",
    "    \n",
    "    #placeholder for dropout\n",
    "    dropout = tf.placeholder(tf.float32, name='dropout')\n",
    "    \n",
    "    #NN Model\n",
    "    logits = get_model(x, dropout)\n",
    "    \n",
    "    #loss function\n",
    "    with tf.name_scope('loss'):\n",
    "        #watchout this line\n",
    "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=y), name='loss')\n",
    "        tf.summary.scalar('loss', loss)\n",
    "        \n",
    "    with tf.name_scope('train'):\n",
    "        train_step = tf.train.AdamOptimizer(LEARNING_RATE).minimize(loss)\n",
    "    \n",
    "    with tf.name_scope('accuracy'):\n",
    "        predicted = tf.argmax(logits,1)\n",
    "        truth = tf.argmax(y,1)\n",
    "        correct_prediction = tf.equal(predicted,truth)\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        confusion_matrix = tf.confusion_matrix(truth, predicted, num_classes=NUM_LABELS)\n",
    "        tf.summary.scalar('accuracy',accuracy)\n",
    "    \n",
    "    summ = tf.summary.merge_all()\n",
    "    saver = tf.train.Saver()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    writer = tf.summary.FileWriter(LOGDIR)\n",
    "    writer.add_graph(sess.graph)\n",
    "    test_writer = tf.summary.FileWriter(TEST_LOGDIR)\n",
    "    \n",
    "    #Training model\n",
    "    print(\"starting Training\\n\")\n",
    "    batch = get_batch(BATCH_SIZE, PATH_TRAIN)\n",
    "    start_time = time.time()\n",
    "    for i in range(1, ITERATIONS + 1):\n",
    "        X, Y = next(batch)\n",
    "        if i % EVAL_EVERY == 0:\n",
    "            #watch this dropout\n",
    "            [train_accuracy, train_loss, s] = sess.run([accuracy, loss, summ], feed_dict={x: X, y: Y, dropout: 0.2})\n",
    "            acc_and_loss = [i, train_loss, train_accuracy * 100]\n",
    "            print('Iteration # {}. Train Loss {:,.2f}. Train Acc: {:,.0f}%'.format(*acc_and_loss))\n",
    "            writer.add_summary(s, i)\n",
    "        if i % (EVAL_EVERY * 20) == 0:\n",
    "            train_confusion_matrix = sess.run([confusion_matrix], feed_dict={x: X, y: Y, dropout: 0.3})\n",
    "            header=LABEL_TO_INDEX_MAP.keys()\n",
    "            #watch this droput\n",
    "            df=pd.DataFrame(np.reshape(train_confusion_matrix, (NUM_LABELS, NUM_LABELS)), index=header)\n",
    "            print('\\nConfusion Matrix:\\n {}\\n'.format(df))\n",
    "            saver.save(sess, os.path.join(LOGDIR, 'model.ckpt'), i)\n",
    "            \n",
    "        sess.run(train_step, feed_dict={x: X, y: Y, dropout: 0.2})\n",
    "    \n",
    "    print('\\nTotal training time: {:0f} seconds\\n'.format(time.time() - start_time))\n",
    "    \n",
    "#def test():\n",
    "    #testing model\n",
    "#    init(PATH_TEST)\n",
    "    batch = get_batch(BATCH_SIZE, PATH_TEST)\n",
    "    total_accuracy = 0\n",
    "    for i in range(ITERATIONS_TEST):\n",
    "        X, Y = next(batch, PATH_TEST)\n",
    "        print(\"tested.\")\n",
    "        #accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        #summ = tf.summary.merge_all()\n",
    "\n",
    "        test_accuracy, s = sess.run([accuracy, summ], feed_dict={x: X, y: Y, dropout: 0.9})\n",
    "        print('Iteration # {}. Test Accuracy: {:.0f}%'.format(i+1, test_accuracy * 100))\n",
    "        total_accuracy += (test_accuracy / ITERATIONS_TEST)\n",
    "        test_writer.add_summary(s,i)\n",
    "        \n",
    "    print('\\nFinal Test Accuracy: {:.0f}%'.format(total_accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ba': 0, 'ju': 1, 'mi': 2, 'nu': 3, 'si': 4, 'ta': 5}\n",
      "starting Training\n",
      "\n",
      "Iteration # 5. Train Loss 5.29. Train Acc: 0%\n",
      "Iteration # 10. Train Loss 3.36. Train Acc: 10%\n",
      "Iteration # 15. Train Loss 3.12. Train Acc: 10%\n",
      "Iteration # 20. Train Loss 2.44. Train Acc: 40%\n",
      "Iteration # 25. Train Loss 3.02. Train Acc: 10%\n",
      "Iteration # 30. Train Loss 3.09. Train Acc: 20%\n",
      "Iteration # 35. Train Loss 2.01. Train Acc: 20%\n",
      "Iteration # 40. Train Loss 2.23. Train Acc: 30%\n",
      "Iteration # 45. Train Loss 1.56. Train Acc: 30%\n",
      "Iteration # 50. Train Loss 2.77. Train Acc: 10%\n",
      "Iteration # 55. Train Loss 1.44. Train Acc: 40%\n",
      "Iteration # 60. Train Loss 1.73. Train Acc: 20%\n",
      "Iteration # 65. Train Loss 1.51. Train Acc: 20%\n",
      "Iteration # 70. Train Loss 1.79. Train Acc: 30%\n",
      "Iteration # 75. Train Loss 1.51. Train Acc: 40%\n",
      "Iteration # 80. Train Loss 1.92. Train Acc: 30%\n",
      "Iteration # 85. Train Loss 1.47. Train Acc: 50%\n",
      "Iteration # 90. Train Loss 1.42. Train Acc: 30%\n",
      "Iteration # 95. Train Loss 1.57. Train Acc: 30%\n",
      "Iteration # 100. Train Loss 1.63. Train Acc: 10%\n",
      "\n",
      "Confusion Matrix:\n",
      "     0  1  2  3  4  5\n",
      "ba  0  0  0  1  0  1\n",
      "ju  0  0  0  1  0  0\n",
      "mi  0  0  1  1  0  0\n",
      "nu  0  2  0  1  0  0\n",
      "si  0  0  0  0  1  0\n",
      "ta  0  0  0  0  0  1\n",
      "\n",
      "Iteration # 105. Train Loss 1.09. Train Acc: 70%\n",
      "Iteration # 110. Train Loss 1.45. Train Acc: 30%\n",
      "Iteration # 115. Train Loss 1.46. Train Acc: 50%\n",
      "Iteration # 120. Train Loss 1.84. Train Acc: 20%\n",
      "Iteration # 125. Train Loss 1.66. Train Acc: 40%\n",
      "Iteration # 130. Train Loss 1.25. Train Acc: 60%\n",
      "Iteration # 135. Train Loss 1.44. Train Acc: 40%\n",
      "Iteration # 140. Train Loss 1.28. Train Acc: 70%\n",
      "Iteration # 145. Train Loss 1.31. Train Acc: 40%\n",
      "Iteration # 150. Train Loss 1.15. Train Acc: 50%\n",
      "Iteration # 155. Train Loss 1.64. Train Acc: 40%\n",
      "Iteration # 160. Train Loss 1.44. Train Acc: 30%\n",
      "Iteration # 165. Train Loss 1.07. Train Acc: 50%\n",
      "Iteration # 170. Train Loss 1.57. Train Acc: 60%\n",
      "Iteration # 175. Train Loss 1.13. Train Acc: 50%\n",
      "Iteration # 180. Train Loss 1.32. Train Acc: 50%\n",
      "Iteration # 185. Train Loss 1.25. Train Acc: 50%\n",
      "Iteration # 190. Train Loss 1.08. Train Acc: 60%\n",
      "Iteration # 195. Train Loss 1.26. Train Acc: 80%\n",
      "Iteration # 200. Train Loss 0.49. Train Acc: 90%\n",
      "\n",
      "Confusion Matrix:\n",
      "     0  1  2  3  4  5\n",
      "ba  1  0  1  0  0  0\n",
      "ju  0  1  0  0  0  0\n",
      "mi  0  0  1  0  0  0\n",
      "nu  0  0  0  2  0  0\n",
      "si  0  0  0  0  1  0\n",
      "ta  0  0  0  0  0  3\n",
      "\n",
      "Iteration # 205. Train Loss 0.69. Train Acc: 80%\n",
      "Iteration # 210. Train Loss 1.16. Train Acc: 50%\n",
      "Iteration # 215. Train Loss 0.68. Train Acc: 70%\n",
      "Iteration # 220. Train Loss 0.88. Train Acc: 60%\n",
      "Iteration # 225. Train Loss 0.74. Train Acc: 70%\n",
      "Iteration # 230. Train Loss 0.89. Train Acc: 80%\n",
      "Iteration # 235. Train Loss 0.71. Train Acc: 80%\n",
      "Iteration # 240. Train Loss 0.78. Train Acc: 70%\n",
      "Iteration # 245. Train Loss 0.83. Train Acc: 70%\n",
      "Iteration # 250. Train Loss 0.58. Train Acc: 80%\n",
      "Iteration # 255. Train Loss 0.51. Train Acc: 90%\n",
      "Iteration # 260. Train Loss 0.57. Train Acc: 70%\n",
      "Iteration # 265. Train Loss 0.68. Train Acc: 70%\n",
      "Iteration # 270. Train Loss 0.40. Train Acc: 90%\n",
      "Iteration # 275. Train Loss 0.63. Train Acc: 80%\n",
      "Iteration # 280. Train Loss 0.53. Train Acc: 80%\n",
      "Iteration # 285. Train Loss 0.33. Train Acc: 90%\n",
      "Iteration # 290. Train Loss 0.67. Train Acc: 60%\n",
      "Iteration # 295. Train Loss 0.45. Train Acc: 80%\n",
      "Iteration # 300. Train Loss 0.59. Train Acc: 80%\n",
      "\n",
      "Confusion Matrix:\n",
      "     0  1  2  3  4  5\n",
      "ba  3  0  0  0  0  0\n",
      "ju  0  0  0  0  1  0\n",
      "mi  0  0  1  0  0  0\n",
      "nu  0  0  0  1  0  0\n",
      "si  0  0  0  0  3  0\n",
      "ta  0  0  0  0  0  1\n",
      "\n",
      "Iteration # 305. Train Loss 0.37. Train Acc: 90%\n",
      "Iteration # 310. Train Loss 0.52. Train Acc: 70%\n",
      "Iteration # 315. Train Loss 0.24. Train Acc: 100%\n",
      "Iteration # 320. Train Loss 0.69. Train Acc: 60%\n",
      "Iteration # 325. Train Loss 0.45. Train Acc: 80%\n",
      "Iteration # 330. Train Loss 0.19. Train Acc: 100%\n",
      "Iteration # 335. Train Loss 0.57. Train Acc: 80%\n",
      "Iteration # 340. Train Loss 0.26. Train Acc: 90%\n",
      "Iteration # 345. Train Loss 0.52. Train Acc: 90%\n",
      "Iteration # 350. Train Loss 0.42. Train Acc: 90%\n",
      "Iteration # 355. Train Loss 0.33. Train Acc: 90%\n",
      "Iteration # 360. Train Loss 0.13. Train Acc: 100%\n",
      "Iteration # 365. Train Loss 0.30. Train Acc: 80%\n",
      "Iteration # 370. Train Loss 0.05. Train Acc: 100%\n",
      "Iteration # 375. Train Loss 0.51. Train Acc: 80%\n",
      "Iteration # 380. Train Loss 0.12. Train Acc: 90%\n",
      "Iteration # 385. Train Loss 0.30. Train Acc: 90%\n",
      "Iteration # 390. Train Loss 0.45. Train Acc: 80%\n",
      "Iteration # 395. Train Loss 0.09. Train Acc: 100%\n",
      "Iteration # 400. Train Loss 0.06. Train Acc: 100%\n",
      "\n",
      "Confusion Matrix:\n",
      "     0  1  2  3  4  5\n",
      "ba  2  0  0  0  0  0\n",
      "ju  0  1  0  0  0  0\n",
      "mi  0  0  0  0  0  0\n",
      "nu  0  0  0  2  0  0\n",
      "si  0  0  0  0  3  0\n",
      "ta  0  0  0  0  0  2\n",
      "\n",
      "Iteration # 405. Train Loss 0.20. Train Acc: 100%\n",
      "Iteration # 410. Train Loss 0.17. Train Acc: 100%\n",
      "Iteration # 415. Train Loss 0.17. Train Acc: 100%\n",
      "Iteration # 420. Train Loss 0.16. Train Acc: 100%\n",
      "Iteration # 425. Train Loss 0.12. Train Acc: 100%\n",
      "Iteration # 430. Train Loss 0.06. Train Acc: 100%\n",
      "Iteration # 435. Train Loss 0.30. Train Acc: 90%\n",
      "Iteration # 440. Train Loss 0.27. Train Acc: 90%\n",
      "Iteration # 445. Train Loss 0.26. Train Acc: 90%\n",
      "Iteration # 450. Train Loss 0.41. Train Acc: 80%\n",
      "Iteration # 455. Train Loss 0.34. Train Acc: 90%\n",
      "Iteration # 460. Train Loss 0.12. Train Acc: 100%\n",
      "Iteration # 465. Train Loss 0.36. Train Acc: 90%\n",
      "Iteration # 470. Train Loss 0.37. Train Acc: 90%\n",
      "Iteration # 475. Train Loss 0.63. Train Acc: 80%\n",
      "Iteration # 480. Train Loss 0.25. Train Acc: 90%\n",
      "Iteration # 485. Train Loss 0.11. Train Acc: 100%\n",
      "Iteration # 490. Train Loss 0.04. Train Acc: 100%\n",
      "Iteration # 495. Train Loss 0.17. Train Acc: 90%\n",
      "Iteration # 500. Train Loss 0.49. Train Acc: 90%\n",
      "\n",
      "Confusion Matrix:\n",
      "     0  1  2  3  4  5\n",
      "ba  3  0  0  0  0  1\n",
      "ju  0  1  0  0  0  0\n",
      "mi  0  0  2  0  0  0\n",
      "nu  0  0  0  2  0  0\n",
      "si  0  0  0  0  0  0\n",
      "ta  0  0  0  0  0  1\n",
      "\n",
      "Iteration # 505. Train Loss 0.11. Train Acc: 90%\n",
      "Iteration # 510. Train Loss 0.05. Train Acc: 100%\n",
      "Iteration # 515. Train Loss 0.52. Train Acc: 80%\n",
      "Iteration # 520. Train Loss 0.12. Train Acc: 100%\n",
      "Iteration # 525. Train Loss 0.16. Train Acc: 90%\n",
      "Iteration # 530. Train Loss 0.04. Train Acc: 100%\n",
      "Iteration # 535. Train Loss 0.28. Train Acc: 90%\n",
      "Iteration # 540. Train Loss 0.04. Train Acc: 100%\n",
      "Iteration # 545. Train Loss 0.08. Train Acc: 100%\n",
      "Iteration # 550. Train Loss 0.10. Train Acc: 100%\n",
      "Iteration # 555. Train Loss 0.03. Train Acc: 100%\n",
      "Iteration # 560. Train Loss 0.03. Train Acc: 100%\n",
      "Iteration # 565. Train Loss 0.09. Train Acc: 100%\n",
      "Iteration # 570. Train Loss 0.21. Train Acc: 90%\n",
      "Iteration # 575. Train Loss 0.10. Train Acc: 90%\n",
      "Iteration # 580. Train Loss 0.82. Train Acc: 70%\n",
      "Iteration # 585. Train Loss 0.01. Train Acc: 100%\n",
      "Iteration # 590. Train Loss 0.30. Train Acc: 80%\n",
      "Iteration # 595. Train Loss 0.14. Train Acc: 90%\n",
      "Iteration # 600. Train Loss 0.35. Train Acc: 90%\n",
      "\n",
      "Confusion Matrix:\n",
      "     0  1  2  3  4  5\n",
      "ba  3  0  0  0  0  0\n",
      "ju  0  2  0  0  0  0\n",
      "mi  0  0  1  0  0  0\n",
      "nu  0  0  0  2  0  0\n",
      "si  0  0  0  0  1  0\n",
      "ta  0  0  0  0  0  1\n",
      "\n",
      "Iteration # 605. Train Loss 0.01. Train Acc: 100%\n",
      "Iteration # 610. Train Loss 0.15. Train Acc: 100%\n",
      "Iteration # 615. Train Loss 0.12. Train Acc: 90%\n",
      "Iteration # 620. Train Loss 0.01. Train Acc: 100%\n",
      "Iteration # 625. Train Loss 0.09. Train Acc: 100%\n",
      "Iteration # 630. Train Loss 0.02. Train Acc: 100%\n",
      "Iteration # 635. Train Loss 0.06. Train Acc: 100%\n",
      "Iteration # 640. Train Loss 0.07. Train Acc: 100%\n",
      "Iteration # 645. Train Loss 0.10. Train Acc: 100%\n",
      "Iteration # 650. Train Loss 0.26. Train Acc: 90%\n",
      "Iteration # 655. Train Loss 0.03. Train Acc: 100%\n",
      "Iteration # 660. Train Loss 0.10. Train Acc: 100%\n",
      "Iteration # 665. Train Loss 0.15. Train Acc: 90%\n",
      "Iteration # 670. Train Loss 0.01. Train Acc: 100%\n",
      "Iteration # 675. Train Loss 0.05. Train Acc: 100%\n",
      "Iteration # 680. Train Loss 0.01. Train Acc: 100%\n",
      "Iteration # 685. Train Loss 0.48. Train Acc: 80%\n",
      "Iteration # 690. Train Loss 0.10. Train Acc: 100%\n",
      "Iteration # 695. Train Loss 0.06. Train Acc: 100%\n",
      "Iteration # 700. Train Loss 0.16. Train Acc: 90%\n",
      "\n",
      "Confusion Matrix:\n",
      "     0  1  2  3  4  5\n",
      "ba  5  0  0  0  0  0\n",
      "ju  0  1  0  0  0  0\n",
      "mi  0  0  1  0  0  0\n",
      "nu  0  0  0  1  0  0\n",
      "si  0  0  0  0  1  0\n",
      "ta  0  0  0  0  0  1\n",
      "\n",
      "Iteration # 705. Train Loss 0.06. Train Acc: 100%\n",
      "Iteration # 710. Train Loss 0.05. Train Acc: 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration # 715. Train Loss 0.04. Train Acc: 100%\n",
      "Iteration # 720. Train Loss 0.08. Train Acc: 100%\n",
      "Iteration # 725. Train Loss 0.02. Train Acc: 100%\n",
      "Iteration # 730. Train Loss 0.03. Train Acc: 100%\n",
      "Iteration # 735. Train Loss 0.01. Train Acc: 100%\n",
      "Iteration # 740. Train Loss 0.02. Train Acc: 100%\n",
      "Iteration # 745. Train Loss 0.15. Train Acc: 90%\n",
      "Iteration # 750. Train Loss 0.04. Train Acc: 100%\n",
      "Iteration # 755. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 760. Train Loss 0.04. Train Acc: 100%\n",
      "Iteration # 765. Train Loss 0.19. Train Acc: 90%\n",
      "Iteration # 770. Train Loss 0.07. Train Acc: 100%\n",
      "Iteration # 775. Train Loss 0.26. Train Acc: 90%\n",
      "Iteration # 780. Train Loss 0.17. Train Acc: 90%\n",
      "Iteration # 785. Train Loss 0.07. Train Acc: 100%\n",
      "Iteration # 790. Train Loss 0.04. Train Acc: 100%\n",
      "Iteration # 795. Train Loss 0.34. Train Acc: 90%\n",
      "Iteration # 800. Train Loss 0.03. Train Acc: 100%\n",
      "\n",
      "Confusion Matrix:\n",
      "     0  1  2  3  4  5\n",
      "ba  2  0  0  0  0  0\n",
      "ju  0  3  0  0  0  0\n",
      "mi  0  0  1  0  0  0\n",
      "nu  0  0  0  2  0  0\n",
      "si  0  0  0  0  1  0\n",
      "ta  0  0  0  0  0  1\n",
      "\n",
      "Iteration # 805. Train Loss 0.08. Train Acc: 100%\n",
      "Iteration # 810. Train Loss 0.14. Train Acc: 90%\n",
      "Iteration # 815. Train Loss 0.13. Train Acc: 90%\n",
      "Iteration # 820. Train Loss 0.02. Train Acc: 100%\n",
      "Iteration # 825. Train Loss 0.03. Train Acc: 100%\n",
      "Iteration # 830. Train Loss 0.02. Train Acc: 100%\n",
      "Iteration # 835. Train Loss 0.03. Train Acc: 100%\n",
      "Iteration # 840. Train Loss 0.02. Train Acc: 100%\n",
      "Iteration # 845. Train Loss 0.06. Train Acc: 100%\n",
      "Iteration # 850. Train Loss 0.01. Train Acc: 100%\n",
      "Iteration # 855. Train Loss 0.12. Train Acc: 90%\n",
      "Iteration # 860. Train Loss 0.03. Train Acc: 100%\n",
      "Iteration # 865. Train Loss 0.01. Train Acc: 100%\n",
      "Iteration # 870. Train Loss 0.02. Train Acc: 100%\n",
      "Iteration # 875. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 880. Train Loss 0.01. Train Acc: 100%\n",
      "Iteration # 885. Train Loss 0.02. Train Acc: 100%\n",
      "Iteration # 890. Train Loss 0.13. Train Acc: 100%\n",
      "Iteration # 895. Train Loss 0.01. Train Acc: 100%\n",
      "Iteration # 900. Train Loss 0.02. Train Acc: 100%\n",
      "\n",
      "Confusion Matrix:\n",
      "     0  1  2  3  4  5\n",
      "ba  2  0  0  0  0  0\n",
      "ju  0  2  0  0  0  0\n",
      "mi  0  0  1  0  0  0\n",
      "nu  0  0  0  2  0  0\n",
      "si  0  0  0  0  3  0\n",
      "ta  0  0  0  0  0  0\n",
      "\n",
      "Iteration # 905. Train Loss 0.15. Train Acc: 90%\n",
      "Iteration # 910. Train Loss 0.11. Train Acc: 90%\n",
      "Iteration # 915. Train Loss 0.02. Train Acc: 100%\n",
      "Iteration # 920. Train Loss 0.01. Train Acc: 100%\n",
      "Iteration # 925. Train Loss 0.06. Train Acc: 100%\n",
      "Iteration # 930. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 935. Train Loss 0.10. Train Acc: 90%\n",
      "Iteration # 940. Train Loss 0.07. Train Acc: 100%\n",
      "Iteration # 945. Train Loss 0.02. Train Acc: 100%\n",
      "Iteration # 950. Train Loss 0.13. Train Acc: 90%\n",
      "Iteration # 955. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 960. Train Loss 0.26. Train Acc: 90%\n",
      "Iteration # 965. Train Loss 0.01. Train Acc: 100%\n",
      "Iteration # 970. Train Loss 0.05. Train Acc: 100%\n",
      "Iteration # 975. Train Loss 0.01. Train Acc: 100%\n",
      "Iteration # 980. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 985. Train Loss 0.01. Train Acc: 100%\n",
      "Iteration # 990. Train Loss 0.01. Train Acc: 100%\n",
      "Iteration # 995. Train Loss 0.01. Train Acc: 100%\n",
      "Iteration # 1000. Train Loss 0.02. Train Acc: 100%\n",
      "\n",
      "Confusion Matrix:\n",
      "     0  1  2  3  4  5\n",
      "ba  1  0  0  0  0  0\n",
      "ju  0  2  0  0  0  0\n",
      "mi  0  0  3  0  0  0\n",
      "nu  0  0  0  3  0  0\n",
      "si  0  0  0  0  1  0\n",
      "ta  0  0  0  0  0  0\n",
      "\n",
      "Iteration # 1005. Train Loss 0.08. Train Acc: 100%\n",
      "Iteration # 1010. Train Loss 0.01. Train Acc: 100%\n",
      "Iteration # 1015. Train Loss 0.02. Train Acc: 100%\n",
      "Iteration # 1020. Train Loss 0.01. Train Acc: 100%\n",
      "Iteration # 1025. Train Loss 0.03. Train Acc: 100%\n",
      "Iteration # 1030. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1035. Train Loss 0.05. Train Acc: 100%\n",
      "Iteration # 1040. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1045. Train Loss 0.01. Train Acc: 100%\n",
      "Iteration # 1050. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1055. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1060. Train Loss 0.02. Train Acc: 100%\n",
      "Iteration # 1065. Train Loss 0.03. Train Acc: 100%\n",
      "Iteration # 1070. Train Loss 0.28. Train Acc: 90%\n",
      "Iteration # 1075. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1080. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1085. Train Loss 0.03. Train Acc: 100%\n",
      "Iteration # 1090. Train Loss 0.01. Train Acc: 100%\n",
      "Iteration # 1095. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1100. Train Loss 0.03. Train Acc: 100%\n",
      "\n",
      "Confusion Matrix:\n",
      "     0  1  2  3  4  5\n",
      "ba  3  0  0  0  0  0\n",
      "ju  0  2  0  0  0  0\n",
      "mi  0  0  2  0  0  0\n",
      "nu  0  0  0  1  0  0\n",
      "si  0  0  0  0  2  0\n",
      "ta  0  0  0  0  0  0\n",
      "\n",
      "Iteration # 1105. Train Loss 0.02. Train Acc: 100%\n",
      "Iteration # 1110. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1115. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1120. Train Loss 0.05. Train Acc: 100%\n",
      "Iteration # 1125. Train Loss 0.03. Train Acc: 100%\n",
      "Iteration # 1130. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1135. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1140. Train Loss 0.03. Train Acc: 100%\n",
      "Iteration # 1145. Train Loss 0.01. Train Acc: 100%\n",
      "Iteration # 1150. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1155. Train Loss 0.01. Train Acc: 100%\n",
      "Iteration # 1160. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1165. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1170. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1175. Train Loss 0.07. Train Acc: 100%\n",
      "Iteration # 1180. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1185. Train Loss 0.01. Train Acc: 100%\n",
      "Iteration # 1190. Train Loss 0.05. Train Acc: 100%\n",
      "Iteration # 1195. Train Loss 0.11. Train Acc: 90%\n",
      "Iteration # 1200. Train Loss 0.01. Train Acc: 100%\n",
      "\n",
      "Confusion Matrix:\n",
      "     0  1  2  3  4  5\n",
      "ba  1  0  0  0  0  0\n",
      "ju  0  1  0  0  0  0\n",
      "mi  0  0  1  0  0  0\n",
      "nu  0  0  0  3  0  0\n",
      "si  0  0  0  0  2  0\n",
      "ta  0  0  0  0  0  2\n",
      "\n",
      "Iteration # 1205. Train Loss 0.06. Train Acc: 100%\n",
      "Iteration # 1210. Train Loss 0.02. Train Acc: 100%\n",
      "Iteration # 1215. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1220. Train Loss 0.01. Train Acc: 100%\n",
      "Iteration # 1225. Train Loss 0.02. Train Acc: 100%\n",
      "Iteration # 1230. Train Loss 0.01. Train Acc: 100%\n",
      "Iteration # 1235. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1240. Train Loss 0.01. Train Acc: 100%\n",
      "Iteration # 1245. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1250. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1255. Train Loss 0.01. Train Acc: 100%\n",
      "Iteration # 1260. Train Loss 0.01. Train Acc: 100%\n",
      "Iteration # 1265. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1270. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1275. Train Loss 0.02. Train Acc: 100%\n",
      "Iteration # 1280. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1285. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1290. Train Loss 0.04. Train Acc: 100%\n",
      "Iteration # 1295. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1300. Train Loss 0.00. Train Acc: 100%\n",
      "\n",
      "Confusion Matrix:\n",
      "     0  1  2  3  4  5\n",
      "ba  3  0  0  0  0  0\n",
      "ju  0  0  0  0  0  0\n",
      "mi  0  0  2  0  0  0\n",
      "nu  0  0  0  1  0  0\n",
      "si  0  0  0  0  3  0\n",
      "ta  0  0  0  0  0  1\n",
      "\n",
      "Iteration # 1305. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1310. Train Loss 0.01. Train Acc: 100%\n",
      "Iteration # 1315. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1320. Train Loss 0.05. Train Acc: 100%\n",
      "Iteration # 1325. Train Loss 0.03. Train Acc: 100%\n",
      "Iteration # 1330. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1335. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1340. Train Loss 0.01. Train Acc: 100%\n",
      "Iteration # 1345. Train Loss 0.09. Train Acc: 90%\n",
      "Iteration # 1350. Train Loss 0.01. Train Acc: 100%\n",
      "Iteration # 1355. Train Loss 0.06. Train Acc: 100%\n",
      "Iteration # 1360. Train Loss 0.02. Train Acc: 100%\n",
      "Iteration # 1365. Train Loss 0.03. Train Acc: 100%\n",
      "Iteration # 1370. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1375. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1380. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1385. Train Loss 0.03. Train Acc: 100%\n",
      "Iteration # 1390. Train Loss 0.01. Train Acc: 100%\n",
      "Iteration # 1395. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1400. Train Loss 0.01. Train Acc: 100%\n",
      "\n",
      "Confusion Matrix:\n",
      "     0  1  2  3  4  5\n",
      "ba  3  0  0  0  0  0\n",
      "ju  0  0  0  0  0  0\n",
      "mi  0  0  0  0  0  0\n",
      "nu  0  0  0  3  0  0\n",
      "si  0  0  0  0  1  0\n",
      "ta  0  0  0  0  0  3\n",
      "\n",
      "Iteration # 1405. Train Loss 0.03. Train Acc: 100%\n",
      "Iteration # 1410. Train Loss 0.00. Train Acc: 100%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration # 1415. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1420. Train Loss 0.02. Train Acc: 100%\n",
      "Iteration # 1425. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1430. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1435. Train Loss 0.01. Train Acc: 100%\n",
      "Iteration # 1440. Train Loss 0.02. Train Acc: 100%\n",
      "Iteration # 1445. Train Loss 0.01. Train Acc: 100%\n",
      "Iteration # 1450. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1455. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1460. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1465. Train Loss 0.02. Train Acc: 100%\n",
      "Iteration # 1470. Train Loss 0.01. Train Acc: 100%\n",
      "Iteration # 1475. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1480. Train Loss 0.01. Train Acc: 100%\n",
      "Iteration # 1485. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1490. Train Loss 0.14. Train Acc: 90%\n",
      "Iteration # 1495. Train Loss 0.02. Train Acc: 100%\n",
      "Iteration # 1500. Train Loss 0.00. Train Acc: 100%\n",
      "\n",
      "Confusion Matrix:\n",
      "     0  1  2  3  4  5\n",
      "ba  2  0  0  0  0  0\n",
      "ju  0  2  0  0  0  0\n",
      "mi  0  0  2  0  0  0\n",
      "nu  0  0  0  0  0  0\n",
      "si  0  0  0  0  2  0\n",
      "ta  0  0  0  0  0  2\n",
      "\n",
      "Iteration # 1505. Train Loss 0.17. Train Acc: 90%\n",
      "Iteration # 1510. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1515. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1520. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1525. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1530. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1535. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1540. Train Loss 0.07. Train Acc: 100%\n",
      "Iteration # 1545. Train Loss 0.05. Train Acc: 100%\n",
      "Iteration # 1550. Train Loss 0.04. Train Acc: 100%\n",
      "Iteration # 1555. Train Loss 0.02. Train Acc: 100%\n",
      "Iteration # 1560. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1565. Train Loss 0.07. Train Acc: 100%\n",
      "Iteration # 1570. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1575. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1580. Train Loss 0.02. Train Acc: 100%\n",
      "Iteration # 1585. Train Loss 0.01. Train Acc: 100%\n",
      "Iteration # 1590. Train Loss 0.08. Train Acc: 100%\n",
      "Iteration # 1595. Train Loss 0.01. Train Acc: 100%\n",
      "Iteration # 1600. Train Loss 0.00. Train Acc: 100%\n",
      "\n",
      "Confusion Matrix:\n",
      "     0  1  2  3  4  5\n",
      "ba  2  0  0  0  0  0\n",
      "ju  0  2  0  0  0  0\n",
      "mi  0  0  1  0  0  0\n",
      "nu  0  0  0  3  0  0\n",
      "si  0  0  0  0  1  0\n",
      "ta  0  0  0  0  0  1\n",
      "\n",
      "Iteration # 1605. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1610. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1615. Train Loss 0.02. Train Acc: 100%\n",
      "Iteration # 1620. Train Loss 0.10. Train Acc: 90%\n",
      "Iteration # 1625. Train Loss 0.03. Train Acc: 100%\n",
      "Iteration # 1630. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1635. Train Loss 0.01. Train Acc: 100%\n",
      "Iteration # 1640. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1645. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1650. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1655. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1660. Train Loss 0.02. Train Acc: 100%\n",
      "Iteration # 1665. Train Loss 0.01. Train Acc: 100%\n",
      "Iteration # 1670. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1675. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1680. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1685. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1690. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1695. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1700. Train Loss 0.03. Train Acc: 100%\n",
      "\n",
      "Confusion Matrix:\n",
      "     0  1  2  3  4  5\n",
      "ba  1  0  0  0  0  0\n",
      "ju  0  1  0  0  0  0\n",
      "mi  0  0  2  0  0  0\n",
      "nu  0  0  0  4  0  0\n",
      "si  0  0  0  0  1  0\n",
      "ta  0  0  0  0  0  1\n",
      "\n",
      "Iteration # 1705. Train Loss 0.01. Train Acc: 100%\n",
      "Iteration # 1710. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1715. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1720. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1725. Train Loss 0.16. Train Acc: 90%\n",
      "Iteration # 1730. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1735. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1740. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1745. Train Loss 0.07. Train Acc: 100%\n",
      "Iteration # 1750. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1755. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1760. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1765. Train Loss 0.16. Train Acc: 90%\n",
      "Iteration # 1770. Train Loss 0.05. Train Acc: 100%\n",
      "Iteration # 1775. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1780. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1785. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1790. Train Loss 0.03. Train Acc: 100%\n",
      "Iteration # 1795. Train Loss 0.05. Train Acc: 100%\n",
      "Iteration # 1800. Train Loss 0.01. Train Acc: 100%\n",
      "\n",
      "Confusion Matrix:\n",
      "     0  1  2  3  4  5\n",
      "ba  3  0  0  0  0  0\n",
      "ju  0  3  0  0  0  0\n",
      "mi  0  0  1  0  0  0\n",
      "nu  0  0  0  0  0  0\n",
      "si  0  0  0  0  2  0\n",
      "ta  0  0  0  0  0  1\n",
      "\n",
      "Iteration # 1805. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1810. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1815. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1820. Train Loss 0.01. Train Acc: 100%\n",
      "Iteration # 1825. Train Loss 0.06. Train Acc: 100%\n",
      "Iteration # 1830. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1835. Train Loss 0.01. Train Acc: 100%\n",
      "Iteration # 1840. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1845. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1850. Train Loss 0.01. Train Acc: 100%\n",
      "Iteration # 1855. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1860. Train Loss 0.08. Train Acc: 90%\n",
      "Iteration # 1865. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1870. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1875. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1880. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1885. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1890. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1895. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1900. Train Loss 0.00. Train Acc: 100%\n",
      "\n",
      "Confusion Matrix:\n",
      "     0  1  2  3  4  5\n",
      "ba  4  0  0  0  0  0\n",
      "ju  0  2  0  0  0  0\n",
      "mi  0  0  1  0  0  0\n",
      "nu  0  0  0  0  0  0\n",
      "si  0  0  0  0  1  0\n",
      "ta  0  0  0  0  0  2\n",
      "\n",
      "Iteration # 1905. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1910. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1915. Train Loss 0.07. Train Acc: 100%\n",
      "Iteration # 1920. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1925. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1930. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1935. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1940. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1945. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1950. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1955. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1960. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1965. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1970. Train Loss 0.01. Train Acc: 100%\n",
      "Iteration # 1975. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1980. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1985. Train Loss 0.02. Train Acc: 100%\n",
      "Iteration # 1990. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 1995. Train Loss 0.00. Train Acc: 100%\n",
      "Iteration # 2000. Train Loss 0.04. Train Acc: 100%\n",
      "\n",
      "Confusion Matrix:\n",
      "     0  1  2  3  4  5\n",
      "ba  1  0  0  0  0  0\n",
      "ju  0  2  0  0  0  0\n",
      "mi  0  0  2  0  0  0\n",
      "nu  0  0  0  2  0  0\n",
      "si  0  0  0  0  2  0\n",
      "ta  0  0  0  0  0  1\n",
      "\n",
      "\n",
      "Total training time: 550.291927 seconds\n",
      "\n",
      "tested.\n",
      "Iteration # 1. Test Accuracy: 50%\n",
      "tested.\n",
      "Iteration # 2. Test Accuracy: 80%\n",
      "tested.\n",
      "Iteration # 3. Test Accuracy: 80%\n",
      "tested.\n",
      "Iteration # 4. Test Accuracy: 90%\n",
      "tested.\n",
      "Iteration # 5. Test Accuracy: 80%\n",
      "tested.\n",
      "Iteration # 6. Test Accuracy: 40%\n",
      "tested.\n",
      "Iteration # 7. Test Accuracy: 60%\n",
      "tested.\n",
      "Iteration # 8. Test Accuracy: 70%\n",
      "tested.\n",
      "Iteration # 9. Test Accuracy: 70%\n",
      "tested.\n",
      "Iteration # 10. Test Accuracy: 70%\n",
      "\n",
      "Final Test Accuracy: 69%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    init(PATH_TRAIN)\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from log/endmodel.ckpt\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Unsuccessful TensorSliceReader constructor: Failed to find any matching files for log/endmodel.ckpt\n\t [[Node: save_1/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_1/Const_0_0, save_1/RestoreV2/tensor_names, save_1/RestoreV2/shape_and_slices)]]\n\nCaused by op 'save_1/RestoreV2', defined at:\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-49-89ee6fd69577>\", line 3, in <module>\n    mysaver = tf.train.Saver()\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1293, in __init__\n    self.build()\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1302, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1339, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 796, in _build_internal\n    restore_sequentially, reshape)\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 449, in _AddRestoreOps\n    restore_sequentially)\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 847, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 1113, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3271, in create_op\n    op_def=op_def)\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1650, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nNotFoundError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to find any matching files for log/endmodel.ckpt\n\t [[Node: save_1/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_1/Const_0_0, save_1/RestoreV2/tensor_names, save_1/RestoreV2/shape_and_slices)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1360\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1361\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1362\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[1;32m-> 1340\u001b[1;33m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    517\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for log/endmodel.ckpt\n\t [[Node: save_1/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_1/Const_0_0, save_1/RestoreV2/tensor_names, save_1/RestoreV2/shape_and_slices)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-89ee6fd69577>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmysaver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mmysaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLOGDIR\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'endmodel.ckpt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, sess, save_path)\u001b[0m\n\u001b[0;32m   1753\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min_graph_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1754\u001b[0m       sess.run(self.saver_def.restore_op_name,\n\u001b[1;32m-> 1755\u001b[1;33m                {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[0;32m   1756\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1757\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_eager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuild_save\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuild_restore\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1135\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1137\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1138\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1353\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1355\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1356\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1357\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1372\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1373\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1374\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1376\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for log/endmodel.ckpt\n\t [[Node: save_1/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_1/Const_0_0, save_1/RestoreV2/tensor_names, save_1/RestoreV2/shape_and_slices)]]\n\nCaused by op 'save_1/RestoreV2', defined at:\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-49-89ee6fd69577>\", line 3, in <module>\n    mysaver = tf.train.Saver()\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1293, in __init__\n    self.build()\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1302, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1339, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 796, in _build_internal\n    restore_sequentially, reshape)\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 449, in _AddRestoreOps\n    restore_sequentially)\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 847, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 1113, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3271, in create_op\n    op_def=op_def)\n  File \"C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1650, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nNotFoundError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to find any matching files for log/endmodel.ckpt\n\t [[Node: save_1/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_1/Const_0_0, save_1/RestoreV2/tensor_names, save_1/RestoreV2/shape_and_slices)]]\n"
     ]
    }
   ],
   "source": [
    "#try restoring model.\n",
    "\n",
    "mysaver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    mysaver.restore(sess, os.path.join(LOGDIR,'endmodel.ckpt'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
